"""
Ù…Ø¯ÛŒØ±ÛŒØª Ø®ÙˆØ§Ù†Ø¯Ù† Ùˆ Ù†ÙˆØ´ØªÙ† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Word Ø¨Ø§ metadata Ú©Ø§Ù…Ù„
"""

from docx import Document
from docx.shared import RGBColor, Pt
from docx.enum.text import WD_COLOR_INDEX
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from datetime import datetime
import hashlib


class WordDocumentHandler:
    """
    Ú©Ù„Ø§Ø³ Ù…Ø¯ÛŒØ±ÛŒØª Ø§Ø³Ù†Ø§Ø¯ Word
    """

    def __init__(self):
        """Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡"""
        pass

    def read_document(self, file_path: str) -> Tuple[str, List[Dict], Dict]:
        """
        Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ Word Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ† + Ø³Ø§Ø®ØªØ§Ø±

        Args:
            file_path: Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„

        Returns:
            tuple: (full_text, headings, metadata)
        """
        from src.utils.logger import info, debug

        doc = Document(file_path)

        full_text_parts = []
        headings = []
        paragraphs_info = []

        para_index = 0

        for para in doc.paragraphs:
            text = para.text.strip()

            # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ù
            para_info = {
                'index': para_index,
                'text': text,
                'style': para.style.name,
                'is_heading': False,
                'heading_level': 0
            }

            if not text:
                full_text_parts.append('')
                para_index += 1
                paragraphs_info.append(para_info)
                continue

            # Ø¨Ø±Ø±Ø³ÛŒ Heading
            style_name = para.style.name.lower()
            if 'heading' in style_name:
                level = 1
                if 'heading 1' in style_name:
                    level = 1
                elif 'heading 2' in style_name:
                    level = 2
                elif 'heading 3' in style_name:
                    level = 3

                headings.append({
                    'text': text,
                    'level': level,
                    'para_index': para_index
                })

                para_info['is_heading'] = True
                para_info['heading_level'] = level

                debug(f"   Heading {level} ÛŒØ§ÙØª Ø´Ø¯: {text[:50]}")

            full_text_parts.append(text)
            paragraphs_info.append(para_info)
            para_index += 1

        full_text = '\n'.join(full_text_parts)

        # Ø§ÛŒØ¬Ø§Ø¯ metadata Ø³Ù†Ø¯
        file_obj = Path(file_path)
        metadata = {
            'source_file': file_obj.name,
            'file_path': str(file_obj.absolute()),
            'file_size': file_obj.stat().st_size,
            'total_paragraphs': para_index,
            'total_headings': len(headings),
            'extracted_at': datetime.now().isoformat(),
            'file_hash': self._calculate_file_hash(file_path)
        }

        info(f"âœ… Ø³Ù†Ø¯ Ø®ÙˆØ§Ù†Ø¯Ù‡ Ø´Ø¯: {metadata['total_paragraphs']} Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§ÙØŒ {len(headings)} Ø¹Ù†ÙˆØ§Ù†")

        return full_text, headings, metadata

    def _calculate_file_hash(self, file_path: str) -> str:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ hash ÙØ§ÛŒÙ„"""
        hasher = hashlib.sha256()
        with open(file_path, 'rb') as f:
            hasher.update(f.read())
        return hasher.hexdigest()[:16]

    def save_chunked_document(self, output_path: str, chunks: List[Dict],
                              source_metadata: Dict, processing_stats: Dict):
        """
        Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ Word Ú†Ø§Ù†Ú©â€ŒØ´Ø¯Ù‡ Ø¨Ø§ ØªÚ¯â€ŒÙ‡Ø§ Ùˆ metadata

        Args:
            output_path: Ù…Ø³ÛŒØ± Ø®Ø±ÙˆØ¬ÛŒ
            chunks: Ù„ÛŒØ³Øª chunkâ€ŒÙ‡Ø§
            source_metadata: metadata ÙØ§ÛŒÙ„ Ø§ØµÙ„ÛŒ
            processing_stats: Ø¢Ù…Ø§Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´
        """
        from src.utils.logger import info

        doc = Document()

        # Ø¹Ù†ÙˆØ§Ù† Ø³Ù†Ø¯
        title = doc.add_heading('Ø³Ù†Ø¯ Ú†Ø§Ù†Ú©â€ŒØ´Ø¯Ù‡ - RAG Workbench', 0)

        # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ù„ÛŒ
        info_para = doc.add_paragraph()
        info_para.add_run('ÙØ§ÛŒÙ„ Ø§ØµÙ„ÛŒ: ').bold = True
        info_para.add_run(f"{source_metadata['source_file']}\n")
        info_para.add_run('ØªØ§Ø±ÛŒØ® Ù¾Ø±Ø¯Ø§Ø²Ø´: ').bold = True
        info_para.add_run(f"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        info_para.add_run('ØªØ¹Ø¯Ø§Ø¯ Chunk: ').bold = True
        info_para.add_run(f"{processing_stats['total_chunks']}\n")
        info_para.add_run('Ø²Ù…Ø§Ù† Ù¾Ø±Ø¯Ø§Ø²Ø´: ').bold = True
        info_para.add_run(f"{processing_stats['total_time']:.2f} Ø«Ø§Ù†ÛŒÙ‡\n")

        doc.add_paragraph()
        doc.add_paragraph('â”€' * 80)
        doc.add_paragraph()

        # Ù†ÙˆØ´ØªÙ† chunkâ€ŒÙ‡Ø§
        for chunk in chunks:
            # ØªÚ¯ chunk
            tag = f"@@-{chunk['chunk_id']}-@@"
            tag_para = doc.add_paragraph()
            tag_run = tag_para.add_run(tag)
            tag_run.bold = True
            tag_run.font.size = Pt(14)
            tag_run.font.color.rgb = RGBColor(0, 102, 204)  # Ø¢Ø¨ÛŒ

            # Ù†ÙˆØ¹ chunk (Parent/Child)
            if chunk.get('is_parent'):
                type_para = doc.add_paragraph()
                type_run = type_para.add_run('ğŸ“¦ Parent Chunk')
                type_run.font.color.rgb = RGBColor(0, 153, 76)  # Ø³Ø¨Ø²
            else:
                type_para = doc.add_paragraph()
                type_run = type_para.add_run('ğŸ“„ Child Chunk')
                type_run.font.color.rgb = RGBColor(204, 102, 0)  # Ù†Ø§Ø±Ù†Ø¬ÛŒ

            # Heading path (Ø§Ú¯Ø± Ø¯Ø§Ø±Ø¯)
            if chunk.get('heading_path'):
                heading_para = doc.add_paragraph()
                heading_para.add_run('ğŸ“ Ù…Ø³ÛŒØ±: ').bold = True
                heading_para.add_run(' Â» '.join(chunk['heading_path']))

            # Ù…ØªÙ† chunk Ø¨Ø§ highlight
            text_para = doc.add_paragraph()
            text_run = text_para.add_run(chunk['text'])

            # highlight Ø¨Ø± Ø§Ø³Ø§Ø³ boundary stage
            stage = chunk['boundary_info'].get('stage', 0)
            if stage == 0:  # Heading
                text_run.font.highlight_color = WD_COLOR_INDEX.YELLOW
            elif stage == 1:  # Pattern
                text_run.font.highlight_color = WD_COLOR_INDEX.BRIGHT_GREEN
            elif stage == 2:  # Coherence
                text_run.font.highlight_color = WD_COLOR_INDEX.TURQUOISE
            elif stage == 3:  # Embedding
                text_run.font.highlight_color = WD_COLOR_INDEX.PINK

            # Metadata
            meta_para = doc.add_paragraph()
            meta_para.style = 'Intense Quote'

            meta_parts = [
                f"ID: {chunk['chunk_id']}",
                f"Ú©Ù„Ù…Ø§Øª: {chunk['word_count']}",
                f"Ø¬Ù…Ù„Ø§Øª: {chunk['sentence_count']}",
                f"Stage: {chunk['boundary_info'].get('stage_name', 'N/A')}",
                f"Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {chunk['boundary_info'].get('confidence', 0):.2f}"
            ]

            if chunk.get('parent_id'):
                meta_parts.append(f"ÙˆØ§Ù„Ø¯: {chunk['parent_id']}")

            if chunk.get('child_ids'):
                meta_parts.append(f"ÙØ±Ø²Ù†Ø¯Ø§Ù†: {len(chunk['child_ids'])}")

            if chunk.get('keywords'):
                meta_parts.append(f"Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡: {', '.join(chunk['keywords'][:3])}")

            meta_para.add_run(' | '.join(meta_parts))

            # ÙØ§ØµÙ„Ù‡
            doc.add_paragraph()
            doc.add_paragraph('â”€' * 80)
            doc.add_paragraph()

        # Ø°Ø®ÛŒØ±Ù‡
        doc.save(output_path)
        info(f"âœ… ÙØ§ÛŒÙ„ Ú†Ø§Ù†Ú©â€ŒØ´Ø¯Ù‡ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {output_path}")

    def extract_paragraph_ids(self, text: str) -> List[int]:
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ù…Ø§Ø±Ù‡ Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ùâ€ŒÙ‡Ø§ Ø§Ø² Ù…ØªÙ†
        (Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø®Øª Ø§Ø±ØªØ¨Ø§Ø· Ø¨ÛŒÙ† chunk Ùˆ Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ù Ø§ØµÙ„ÛŒ)
        """
        # Ø§ÛŒÙ† Ù…ØªØ¯ Ø¯Ø± ÙØ§Ø²Ù‡Ø§ÛŒ Ø¨Ø¹Ø¯ÛŒ ØªÚ©Ù…ÛŒÙ„ Ù…ÛŒâ€ŒØ´ÙˆØ¯
        return []


# ØªØ³Øª
if __name__ == "__main__":
    print("ğŸ§ª ØªØ³Øª word_handler.py\n")

    handler = WordDocumentHandler()

    # ØªØ³Øª Ø®ÙˆØ§Ù†Ø¯Ù† (Ø§Ú¯Ø± ÙØ§ÛŒÙ„ ØªØ³Øª ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯)
    test_file = "./Word_File_for_Test/Word_File_for_Test.docx"
    if Path(test_file).exists():
        text, headings, metadata = handler.read_document(test_file)
        print(f"âœ… Ù…ØªÙ† Ø®ÙˆØ§Ù†Ø¯Ù‡ Ø´Ø¯: {len(text)} Ú©Ø§Ø±Ø§Ú©ØªØ±")
        print(f"âœ… {len(headings)} Ø¹Ù†ÙˆØ§Ù† ÛŒØ§ÙØª Ø´Ø¯")
        print(f"âœ… Metadata: {metadata}")
    else:
        print(f"âš ï¸ ÙØ§ÛŒÙ„ ØªØ³Øª ÛŒØ§ÙØª Ù†Ø´Ø¯: {test_file}")